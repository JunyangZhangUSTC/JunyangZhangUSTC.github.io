---
title: '昇腾集群部署DeepSeek疯狂踩坑'
date: 2025-02-23
permalink: /posts/2025/02/thinking-4/
categories:
  - Tools
tags:
  - DeepSeek
  - Ascend
---

接到辅助学校部署DeepSeek的任务，终于部署起来了，发现还是挺好用的。最近任务紧，等过几天闲下来写个踩坑记录。

<details>
<summary><strong>原先的吐槽</strong></summary>

<p>接到辅助学校部署DeepSeek的任务，很急。现在是凌晨1:10，是什么，让我忍不住要写这个笔记，我实在绷不住了啊！！！</p>
<h3>魔乐社区的奇妙体验</h3>
<p>我真傻，真的，我只知道魔乐社区下载很快，我只知道魔乐社区是华为推出的，应该很兼容，不知道这是一个多大的坑。</p>
<ul>
<li>魔乐社区下载工具不支持python3.11，但是华为MindIE官方镜像里的python是3.11
<ul>
<li>有人说，你装个python3.10不就行了吗？但是对不起，系统是华为自己的OpenEule，要装python自己编译。这任务火烧眉毛了还自己编译python呢.</li>
<li>有人说，你为什么不在宿主机下载，映射到容器里？我试了，魔乐社区的工具虽然下载到目标目录里，但是大文件是个软连接，都存储在<code>~/.cache</code>下，我在容器里根本读取不到。我好不容易配置好了容器还得重启一个改映射？？</li>
<li>有人说，他不是还支持git吗。很好，他需要git lfs。但是openeuler仓库的git-lfs没有引入到主线版本和正式版本中，只能自己找源码编译。</li>
</ul>
</li>
</ul>
<p>一切都回来了，想用的话，正反都要自己编译个软件先。</p>
<p>不是，我真的第一次见指定了目标下载地址，竟然给我整了个指向home目录的软链接？我要是home目录磁盘小了还装不下了？？？</p>
<h3>双机直连好多坑</h3>
<p>我们搞了个两台昇腾服务器直连，显卡互相之间访问，这应该是最快的方法吧，就想着能算的快一点，大家用户体验好一点。</p>
<p>但是完全没想到的是，昇腾的多机多卡部署竟然需要每个显卡必须配置网关，直连根本没有网关。不是，你都能直连了，传就是了为啥要设置网关啊！！</p>
<p>程序不语，只是一味的报错。<strong>我真傻，真的。</strong></p>
<h3>时灵时不灵的自动部署工具</h3>
<p>本来我是想直接部署 <code>MindCluster</code>的，结果 A900T 在 OpenEuler_22.03LTS-SP4 上不支持<code>ascend-deployer</code>自动部署，给我整晕了，服务器是华为的、系统是华为的、部署工具也是华为的，加在一起咋不能用了……</p>

</details>

## 性能测试

首先我得说下定量情况，**使用更多的机器部署一个模型实例，在有限资源情况下将更多的显存留给用户的KV Cache是个更好的选择**。这样可以大大提高吞吐量，让更多用户请求同时计算，保持服务的稳定、不会拥塞。虽然因为多机间传输、Batch较大导致生成速度略微降低，但是总比让用户排队体验更好吧。当然，如果你的计算资源非常充足，开多个实例用PD分离显然是个更好的选择。

### 并发能力

先测试客户端不同并发访问量（Concurrency）的情况。测试环境：
- 模型：DeepSeek-R1 671B，W8A8
- 输入token：512；输出token：512
- 部署：4台机器，每台8卡910B，RoCE交换机连接

**吞吐量：** 首先测试吞吐量。下图展示平均吞吐量和生成速度。可以看到吞吐量和平均生成token速度的趋势是保持一致的，并且在并发量400左右达到瓶颈，后续增加并发也保持稳定。虽然服务端平均吞吐保持稳定，但是每个客户端的生成速度明显下降（8->1）。这是符合直觉的，并发量增大，每个客户端的生成速度相应降低了，同时服务端达到性能瓶颈保持稳定。

![吞吐量测量](/images/blogs/thinking4/Throughput.png)

**延迟：** 再说延迟方面，lpct是首token总时延/输入总token数，单位 ms。因为这里输入总token数保持不变，所以lpct和First Token Time保持一致。这里令人意外的点是，随着并发量上升，First Token Time的增长是先慢后快，而Decode Time是先快后平稳。也就是说，Prefill阶段在400并发前比较平稳，这个和吞吐量的分析一致，说明计算资源在400并发前是比较充足的。但是Decode阶段在600并发前却持续走高，这也许说明在600并发前，Decode阶段一直是memory bound的，受限于GPU内的IO带宽，在600并发后达到compute bound。这里的概念可以参考[LLM Roofline](https://arxiv.org/abs/2402.16363)相关研究。

![延迟测量](/images/blogs/thinking4/Latency.png)

**其他时延：** 测试的Tokenizer和Detokenizer的时延都比较平稳，Detokenizer的时延大概是Tokenizer的3～5倍，都在几毫秒级别。另一点是First Token Time和Decode Time的方差特别大，说明服务有点不稳定。

所以如果你也是4台机器每台8卡910B部署 W8A8 的 671B DeepSeek，输入输出设置512tokens的话，也许并发量设置在500是个不错的选择，但是显然并发量1000也可以稳稳撑住。后面再详细测一下输入输出token数量差异很大情况下的结果。


## 部署流程

部署流程有个前几天刚出的文档：[部署推理服务](https://support.huaweicloud.com/bestpractice-modelarts/modelarts_ds_infer_0006.html)。
我是手动部署的，据说自动部署也很好用，后面会写一些坑。

- 最好同时阅读昇腾DeepSeek-R1模型库的[文档](https://www.hiascend.com/software/modelzoo/models/detail/68457b8a51324310aad9a0f55c3e56e3)，建议互相参考，其中包含一些错误处理。
- docker启动时，加上`--shm-size 500g`防止内存溢出，有的文档里没有。
- 模型权重文件夹必须设置权限 `chmod -R 750 {/path-to-weights}`，非常令人痛苦的教训。
- **查看报错日志：** 如果老是崩溃实在找不到问题，可以自己找地方建立一个日志文件夹`your_path/plog`，然后 `export ASCEND_WORK_PATH=your_path/plog` 到日志文件夹。运行完后，在 `your_path/plog/log/debug/plog/` 下执行 `grep "ERROR" ./*` 可以看到详细报错。
- **算子库报错日志：** 这个相关的日志可参考昇腾DeepSeek-R1模型库的[文档](https://www.hiascend.com/software/modelzoo/models/detail/68457b8a51324310aad9a0f55c3e56e3) 的“日志收集”章节。
- **网络连接闪断：** 如果实在不确定是否有网络链接问题，可以使用脚本测试通信算子，阅读[文档](https://bbs.huaweicloud.com/blogs/415301)。如果报错找不到MPI相关的动态链接库，可以加上 `export LD_LIBRARY_PATH=/home/mpich/lib/:/usr/local/Ascend/ascend-toolkit/8.0.RC3/aarch64-linux/lib64:$LD_LIBRARY_PATH`，请注意修改`mpich`的位置和`ascend-toolkit/8.0.RC3`的版本。

注意：文档里说的这一步检查物理链接，但是没说会输出什么，如果什么都没输出是不对的啊，正常的是有输出链接情况的！
```shell
# 检查物理链接
for i in {0..7}; do hccn_tool -i $i -lldp -g | grep Ifname; done 
```

## 硬件双机背板直连的情况

我们用了多种部署方式，其中有个实例用了双机背板直连（2台8卡64G），有点坑需要单独处理。

因为检测工具需要检测网关正确：

``` shell
# 查看网关是否配置正确  
for i in {0..7}; do hccn_tool -i $i -gateway -g ; done
```


而直连没有网关，所以可以配置网关为每个GPU自己，方法：

```shell
# 设置第0张卡的网关为 192.168.11.100
hccn_tool -i 0 -gateway -s gateway 192.168.11.100
```

同时可以考虑将GPU检测对象设置为另一台机器的GPU IP，检测连通性，方法：
```shell
# 设置检测对象ip，设置第0张卡的检测对象 192.168.11.200
hccn_tool -i 0 -netdetect -s address 192.168.11.200
```

配置好后可以通过单独测试本机和另一台机器的GPU IP保证连通信：测试npu之间的连通性：使用 `-netdetect` 配置当前npu需要检测的另一个npu的地址，然后使用`-net_health` 来检测是否连接正常。如果成功会显示 `net health status: Success` 错误的话显示 `net health status: Receive timeout`。
```shell
# address是目标GPU IP
hccn_tool -i 0 -netdetect -s address ${adress}
```

别忘了TLS校验为0
```shell
# 检查NPU底层tls校验行为一致性，建议全0
for i in {0..7}; do hccn_tool -i $i -tls -g ; done | grep switch
# NPU底层tls校验行为置0操作
for i in {0..7};do hccn_tool -i $i -tls -s enable 0;done
```

参考：[HCCN Tool接口文档](https://support.huawei.com/enterprise/zh/doc/EDOC1100303317/eb173a4e)。

## 四机部署的镜像问题

MindIE的T3.1镜像无法拉起32卡671B模型，同时会导致W8A8模型无法4机部署，但是可以支持W8A8模型2机部署，如果需要4机部署回退镜像版本。

## 服务化配置

服务化配置里有很多细致的参数需要设置，参考[配置参数说明文档](https://www.hiascend.com/document/detail/zh/mindie/100/mindieservice/servicedev/mindie_service0285.html)。写的挺详细的。

- 如果想对所有IP提供服务（不推荐，只是因为我们的服务器是独立内网，所以为了测试方便设置，正式服务时会关闭），设置 `allowAllZeroIpListening` 为`true`，`ipAddress` 为`0.0.0.0`。
- 配置文件中有个参数 `maxIterTimes` 会限制最大生成token数量，记得修改，参考[配置参数说明文档](https://www.hiascend.com/document/detail/zh/mindie/100/mindieservice/servicedev/mindie_service0285.html)。
- 强烈建议 `MaxSeqLen` 和 `maxPrefillTokens` 配置相同大小，可以规避重计算问题，不然可能导致一直无效计算并且阻塞服务。
- 保险起见，可根据业务负载从小数值设置 `maxPrefillBatchSize` 逐步增大，防止出现资源不足。
- 可开启电源高性能模式，参考[说明文档](https://www.hiascend.com/document/detail/zh/canncommercial/700/modeldevpt/ptmigr/AImpug_000059.html)，可以提升约20%性能。

后面我单独测试调度策略情况。



---


持续更新中......









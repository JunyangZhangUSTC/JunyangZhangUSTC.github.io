---
title: '基于Scaling Law的AGI之路是否正在让我们变得更平均？'
date: 2025-02-16
permalink: /posts/2025/02/thinking-3/
categories:
  - Thoughts
tags:
  - LLM
  - AGI
---

当前的大模型，让高端平庸化、让低端模糊化、让其他的懒惰化。  ————我自己

以下内容没有经过考证，只是一些随想，也不一定正确，大家看看就好，欢迎讨论。

## 一些小观察

### 体制内的大写手

最近，我看到了一些有趣的分享。一位体制内的资深写手分享了他使用DeepSeek的经历。
平时，他需要撰写一些有深度、有高度的文件。
最近他尝试用DeepSeek来生成这些内容。
然而他发现，使用DeepSeek来写这些文件所花费的时间不比自己写少，甚至更加耗费精力。
因为他不得不频繁地让DeepSeek进行调整，而有时调整后的内容反而会更糟。
最后他得出了一个结论：对于新进文员来说，使用大模型有帮助；但对于他这样的资深写手而言，自己动手更高效，质量更有保障。

### 我自己的科研经历

作为研究深度学习推理加速研究的博士生，我经常需要写代码，我自己也时常借助大模型完成一些模式化的代码。
然而，当我进行一些真正具有创新性的工作，尤其是在底层代码开发方面，我发现大模型根本无法满足我的需求。
它生成的代码漏洞百出，尽管我反复纠正，它依然无法达到预期，尤其在像CUDA编程、创新方法这种专业或者全新的领域。
因此，我只将它用于一些辅助性、简单的任务，比如绘图代码。而真正需要创新的工作，我仍然是完全自己操刀，我更有把握。



## 基础：当前的AGI之路

目前，AGI的路径主要是在深度学习的基础上进一步发展而来。研究人员发现了“scaling law”：只要有足够多的数据，模型的“智慧”就会自然而然地涌现。
因此，这条道路有两个核心要素：深度学习技术和scaling law。

深度学习能够自动提取数据中的特征，并学习数据之间的内在关系。换句话说，深度学习提供了一种极其复杂的高维度拟合方法，使得模型能够捕捉数据的分布特征，从而生成与训练数据相似的输出。
而scaling law的核心是，模型需要足够多且质量高的数据，才能顺利进行训练，或帮助大模型更好地模仿人类智慧。

但深度学习本质还是一种统计方法，它通过统计训练数据的分布，使得输出结果尽可能接近训练数据的特点。在这种情况下，模型的输出往往是“平均化”的，既不是最优解，也不是最差解，通过高质量的数据筛选，甚至能达到“中上等”的水平。

小总结：当前大模型技术的输出不是最优的
- 基于Scaling Law的路线需要大量数据，而最高质量的数据量并达不到Scaling Law的需求，训练数据本身质量良莠不齐。
- 深度学习技术是对训练数据的拟合，所以输出的结果是最好和最坏之间的“中间”情况，偶有妙手，但大规模统计意义上仍然是平均。


## 过渡：人们在变得平均


随着大模型带来的便利和效率提升，许多人开始习惯于通过模型生成看似合适的结果，而不再进行深入的思考。
尤其是在领导认为AI能够提高效率，让你工作量增大的时候。
虽然这些结果可能并不能达到专业人士深入思考后得出的结论，但它们足够方便，而且能满足交付（当前，未来交付要求会提升）。
这就是我说的，**大模型正在让高端平庸化。**

对于那些专业水平较普通的人来说，大模型可以帮助他们生成超出自己能力范围的内容。
虽然这有可能让他们学到一些新东西，但也有潜在的风险，尤其是在代码生成领域，模型可能会生成一些看似正确但实际上存在隐患的代码，但如果使用者缺乏足够的专业水平，往往难以发现这些潜在问题。
这也就是我所说的 **“低端模糊化”的原因。**

对于大多数处于中等水平的人来说，他们通过大模型生成了和自己水平“差不多”的内容后，往往不再深思熟虑，直接使用结果。
这种依赖于自动生成内容的习惯，可能会让思维变得迟钝、懒惰，进而影响进一步提升。这就是我说的 **让其他的懒惰化**。

人们能否通过让大模型学习更高质量的数据来提升效果？当然可以，但却达不到Scaling Law的规模。高质量的数据始终是少数，如何筛选出这些数据、需要多少专家，甚至如果能筛选出来，这么小规模的数据是否足够支撑智能的涌现，仍然是个巨大的问题。所以我认为吧，当前的AGI之路正在无意间引导我们走向“平均化”。

好消息是，这个平均也是比大模型出现之前所有人的平均要高很多了，这也是社会的进步，AI从各方面推动了社会发展是毫无疑问的。


## 未来：如何改进？


人类的欲望是无止境的，要求也会不断提高。当人们逐渐适应了大模型带来的“平均”输出，基准线也会随之上升，推动科技和社会的进步。因此，尽管大模型可能让社会变得更加“平均”，它也有可能推动更大的创新和进步。
那么，我们该如何改进现状呢？我不清楚，猜猜看。短期内，高质量的数据是关键。未来可能会有专门的团队、组织或公司专门生产高质量的数据集。而在这一过程中，高质量的评判标准也至关重要，因此需要具备专业水平的专家来进行评估。

其次，现有的大模型仍然依赖于scaling law，但这不一定是唯一的道路，也不一定是正确的道路。
十几年前，Alpha Go通过学习大量人类棋谱来击败李世石，尽管李世石仍然赢了一盘，而其后改进版则不再依赖人类棋谱，而是通过自我对弈不断进化，人类再难获胜。
围棋是一个可以量化目标的活动，而许多现实中的任务并没有明确的量化目标，因此围棋上的方法难以直接应用到其他领域。
但就像Alpha Go的进化过程一样，未来的模型改进或许不再需要大量的高质量数据，而只需少量的关键特征即可达到预期效果。类似人类的学习过程。毕竟，我们并不需要看遍成百上千、各式各样的飞机才能知道飞机长什么样。

